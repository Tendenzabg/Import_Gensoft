import streamlit as st
import pandas as pd
import io
from datetime import datetime

# ============================================================
# –ù–ê–°–¢–†–û–ô–ö–ò –ù–ê –°–¢–†–ê–ù–ò–¶–ê–¢–ê
# ============================================================
st.set_page_config(
    page_title="–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ —Ñ–∞–π–ª–æ–≤–µ Nike",
    page_icon="üëü",
    layout="wide",
)

# ============================================================
# –†–ï–ß–ù–ò–¶–ò
# ============================================================

# Division -> –ö–∞—Ç–µ–≥–æ—Ä–∏—è BG
DIVISION_MAP = {
    'APP': '–î—Ä–µ—Ö–∏',
    'FTW': '–û–±—É–≤–∫–∏',
    'EQU': '–ê–∫—Å–µ—Å–æ–∞—Ä–∏',
}

# Gender -> GEN.BG
GENDER_MAP = {
    'MENS': '–ú—ä–∂–µ',
    'WOMENS': '–ñ–µ–Ω–∏',
    'GIRLS': '–ú–æ–º–∏—á–µ—Ç–∞',
    'BOYS': '–ú–æ–º—á–µ—Ç–∞',
    'YOUTH UNISEX': '–Æ–Ω–æ—à–∏ –£–Ω–∏—Å–µ–∫—Å',
    'INFANT UNISEX': '–ë–µ–±–µ—Ç–∞ –£–Ω–∏—Å–µ–∫—Å',
    'ADULT UNISEX': '–í—ä–∑—Ä–∞—Å—Ç–Ω–∏ –£–Ω–∏—Å–µ–∫—Å',
    'CHILD UNISEX': '–î–µ—Ü–∞ —É–Ω–∏—Å–µ–∫—Å',
    'UNISEX': '–£–Ω–∏—Å–µ–∫—Å',
    'Youth unisex': '–ú–ª–∞–¥–µ–∂–∏ —É–Ω–∏—Å–µ–∫—Å',
    'Boys pre school': '–ú–æ–º—á–µ—Ç–∞ –ø—Ä–µ–¥ —É—á–∏–ª–∏—â–Ω–∞',
    'Boys toddler': '–ú–æ–º—á–µ—Ç–∞ –º–∞–ª–∫–∏ –¥–µ—Ü–∞',
    'Boys grade schl': '–ú–æ–º—á–µ—Ç–∞ –Ω–∞—á–∞–ª–Ω–æ —É—á—É–ª–∏—â–µ',
    'KIDS BOYS': '–ú–æ–º—á–µ—Ç–∞',
    'KIDS GIRLS': '–ú–æ–º–∏—á–µ—Ç–∞',
    'KIDS-LITTLE KIDS': '–ú–∞–ª–∫–∏ –¥–µ—Ü–∞',
    'Youth': '–ú–ª–∞–¥–µ–∂–∏',
    'GRD SCHOOL UNSX': '–£–Ω–∏—Å–µ–∫—Å',
    'GRD SCHOOL UNS': '–î–µ—Ü–∞ —É–Ω–∏—Å–µ–∫—Å',
    'PRE SCHOOL UNSX': '–î–µ—Ü–∞ —É–Ω–∏—Å–µ–∫—Å',
    'TODDLER UNISEX': '–£–Ω–∏—Å–µ–∫—Å',
}

# GEN.BG -> –ö–∞—Ç–µ–≥–æ—Ä–∏—è_1
SESSO_MAP = {
    '–ú—ä–∂–µ': '–ú—ä–∂–µ',
    '–ñ–µ–Ω–∏': '–ñ–µ–Ω–∏',
    '–ú–æ–º–∏—á–µ—Ç–∞': '–î–µ—Ü–∞',
    '–ú–æ–º—á–µ—Ç–∞': '–î–µ—Ü–∞',
    '–Æ–Ω–æ—à–∏ –£–Ω–∏—Å–µ–∫—Å': '–î–µ—Ü–∞',
    '–ë–µ–±–µ—Ç–∞ –£–Ω–∏—Å–µ–∫—Å': '–î–µ—Ü–∞',
    '–í—ä–∑—Ä–∞—Å—Ç–Ω–∏ –£–Ω–∏—Å–µ–∫—Å': '–£–Ω–∏—Å–µ–∫—Å',
    '–î–µ—Ü–∞ —É–Ω–∏—Å–µ–∫—Å': '–î–µ—Ü–∞',
    '–£–Ω–∏—Å–µ–∫—Å': '–£–Ω–∏—Å–µ–∫—Å',
    '–ú–ª–∞–¥–µ–∂–∏ —É–Ω–∏—Å–µ–∫—Å': '–î–µ—Ü–∞',
    '–ú–æ–º—á–µ—Ç–∞ –ø—Ä–µ–¥ —É—á–∏–ª–∏—â–Ω–∞': '–î–µ—Ü–∞',
    '–ú–æ–º—á–µ—Ç–∞ –º–∞–ª–∫–∏ –¥–µ—Ü–∞': '–î–µ—Ü–∞',
    '–ú–æ–º—á–µ—Ç–∞ –Ω–∞—á–∞–ª–Ω–æ —É—á—É–ª–∏—â–µ': '–î–µ—Ü–∞',
    '–ú–∞–ª–∫–∏ –¥–µ—Ü–∞': '–î–µ—Ü–∞',
    '–ú–ª–∞–¥–µ–∂–∏': '–î–µ—Ü–∞',
}

# –ö–∞—Ç–µ–≥–æ—Ä–∏—è_1 -> –ø—Ä–µ—Ñ–∏–∫—Å –∑–∞ –ö–∞—Ç–µ–≥–æ—Ä–∏—è_2
CATEGORY2_PREFIX = {
    '–ú—ä–∂–µ': '–ú—ä–∂–∫–∏',
    '–ñ–µ–Ω–∏': '–î–∞–º—Å–∫–∏',
    '–î–µ—Ü–∞': '–î–µ—Ç—Å–∫–∏',
    '–£–Ω–∏—Å–µ–∫—Å': '–£–Ω–∏—Å–µ–∫—Å',
    '–ú–æ–º—á–µ—Ç–∞': '–î–µ—Ç—Å–∫–∏',
    '–ú–æ–º–∏—á–µ—Ç–∞': '–î–µ—Ç—Å–∫–∏',
}

# TIPO (Silhouette EN) -> TIPO.BG (–≤–≥—Ä–∞–¥–µ–Ω —Ä–µ—á–Ω–∏–∫ –æ—Ç SOFIA Traduzioni)
TIPO_MAP = {
    'Sneakers': '–ú–∞—Ä–∞—Ç–æ–Ω–∫–∏',
    'T-shirt': '–¢–µ–Ω–∏—Å–∫–∞',
    'Shirt': '–†–∏–∑–∞',
    'Sweatshirt': '–°—É–∏—Ç—à—ä—Ä—Ç',
    'Hat': '–®–∞–ø–∫–∞',
    'Jacket': '–Ø–∫–µ',
    'Pants': '–ü–∞–Ω—Ç–∞–ª–æ–Ω',
    'Shorts': '–ö—ä—Å –ø–∞–Ω—Ç–∞–ª–æ–Ω',
    'Socks': '–ß–æ—Ä–∞–ø–∏',
    'Body': '–ë–æ–¥–∏',
    'Sandals': '–°–∞–Ω–¥–∞–ª–∏',
    'SHORT SLEEVE TOP': '–¢–µ–Ω–∏—Å–∫–∞',
    'LOW TOP': '–ú–∞—Ä–∞—Ç–æ–Ω–∫–∏',
    'UPPER THIGH LENGTH SHORT': '–ö—ä—Å –ø–∞–Ω—Ç–∞–ª–æ–Ω',
    'MID THIGH LENGTH SHORT': '–ö—ä—Å –ø–∞–Ω—Ç–∞–ª–æ–Ω',
    'SHORT SLEEVE T-SHIRT': '–¢–µ–Ω–∏—Å–∫–∞',
    'KNEE LENGTH SHORT': '–ö—ä—Å –ø–∞–Ω—Ç–∞–ª–æ–Ω',
    'HOODED FULL ZIP LS TOP': '–°—É–∏—Ç—à—ä—Ä—Ç',
    'FULL LENGTH PANT': '–ü–∞–Ω—Ç–∞–ª–æ–Ω',
    'CREW SOCK': '–ß–æ—Ä–∞–ø–∏',
    'THREE QUARTER HIGH': '–ö–µ—Ü–æ–≤–µ',
    'FULL LENGTH TIGHT': '–ö–ª–∏–Ω',
    'HIGH TOP': '–ö–µ—Ü–æ–≤–µ',
    'LONG SLEEVE TOP': '–°—É–∏—Ç—à—ä—Ä—Ç',
    'SLEEVELESS TOP': '–¢–æ–ø',
    'HIP LENGTH HOODED JKT': '–Ø–∫–µ',
    'HOODED LONG SLEEVE TOP': '–°—É–∏—Ç—à—ä—Ä—Ç',
    'DUFFEL GRIP DRUM': '–ß–∞–Ω—Ç–∞',
    'FOOTIE SOCK': '–ß–æ—Ä–∞–ø–∏',
    'WAIST LENGTH JKT': '–Ø–∫–µ',
    'ANKLE LENGTH TIGHT': '–ö–ª–∏–Ω',
    'HIP LENGTH HOODED VEST': '–ï–ª–µ–∫',
    'SMALL ITEMS WAISTPACKS': '–ß–∞–Ω—Ç–∞',
    'BAG - WAISTPACK': '–ß–∞–Ω—Ç–∞',
    'HIP LENGTH VEST': '–ï–ª–µ–∫',
    'ANKLE LENGTH PANT': '–ü–∞–Ω—Ç–∞–ª–æ–Ω',
    'THIGH LENGTH HOODED JKT': '–Ø–∫–µ',
    'HIP LENGTH JKT': '–Ø–∫–µ',
    'NO SHOW SOCK': '–ß–æ—Ä–∞–ø–∏',
    'BACKPACK': '–†–∞–Ω–∏—Ü–∞',
    'SHORT SLEEVE POLO': '–¢–µ–Ω—Å–∫–∞ –ø–æ–ª–æ',
    'CLUB BAG': '–ß–∞–Ω—Ç–∞',
    'ONE QUARTER SOCK': '–ß–æ—Ä–∞–ø–∏',
    'BRA': '–ë—é—Å—Ç–∏–µ',
    'SHORT': '–ö—ä—Å –ø–∞–Ω—Ç–∞–ª–æ–Ω',
    'TANK TOP/SINGLET': '–ë—é—Å—Ç–∏–µ',
    'ADJUSTABLE CAP': '–®–∞–ø–∫–∞',
    'WARM UP': '–ï–∫–∏–ø',
    'SHINGUARD': '–ü—Ä–µ–¥–ø–∞–∑–Ω–∏ –∫–æ—Ä–∏',
    'MID THIGH LENGTH TIGHT': '–ö—ä—Å –ø–∞–Ω—Ç–∞–ª–æ–Ω',
    'BUCKET HAT': '–®–∞–ø–∫–∞',
    'MID SHORT W MID TGH TGT': '–ö—ä—Å –ø–∞–Ω—Ç–∞–ª–æ–Ω',
    'UPPER SHORT W UPP TGH TGT': '–ö—ä—Å –ø–∞–Ω—Ç–∞–ª–æ–Ω',
    'UPPER THIGH LENGTH TIGHT': '–¢–µ–Ω–∏—Å–∫–∞',
    'UNITARD/LEOTARD': '–ë–æ–¥–∏',
    'WAIST LENGTH HOODED JKT': '–Ø–∫–µ',
    'BEANIE': '–®–∞–ø–∫–∞',
    'KNIT TOP': '–ñ–∏–ª–µ—Ç–∫–∞',
    'ONE-QUARTER SOCK': '–ß–æ—Ä–∞–ø–∏',
    'TWO PIECE SET': '–ö–æ–º–ø–ª–µ–∫—Ç',
    'S/S TEE': '–¢–µ–Ω–∏—Å–∫–∞',
    'BOXER/BRIEF': '–ë–æ–∫—Å–µ—Ä–∫–∏',
    'FRENCH TERRY SET': '–ö–æ–º–ø–ª–µ–∫—Ç',
    'LEGGING SET': '–ö–æ–º–ø–ª–µ–∫—Ç',
    '3PK CREW SOCK': '–ß–æ—Ä–∞–ø–∏',
    'TRICOT SET': '–ö–æ–º–ø–ª–µ–∫—Ç',
    'DRI-FIT SHORT': '–ö—ä—Å –ø–∞–Ω—Ç–∞–ª–æ–Ω',
    'TANK TOP': '–ü–æ—Ç–Ω–∏–∫',
    'KNIT SHORT SET': '–°–ø–æ—Ä—Ç–µ–Ω –µ–∫–∏–ø',
    'ONE PIECE': '–ö—ä—Å –≥–∞—â–µ—Ä–∏–∑–æ–Ω',
    'MID SHORT W KNEE TGT': '–ö—ä—Å –ø–∞–Ω—Ç–∞–ª–æ–Ω',
    'UPPER SHORT W MID TGH TGT': '–ö—ä—Å –ø–∞–Ω—Ç–∞–ª–æ–Ω',
    'G NP DF TANK': '–ü–æ—Ç–Ω–∏–∫',
}

# –¢—ä—Ä–≥–æ–≤—Å–∫–∏ —Ü–µ–Ω–æ–≤–∏ —Ç–æ—á–∫–∏
PRICE_POINTS = [
    5, 9, 15, 19, 25, 29, 35, 39, 45, 49,
    55, 59, 65, 69, 75, 79, 85, 89, 95, 99,
    105, 109, 115, 119, 125, 129, 135, 139, 145, 149,
    155, 159, 165, 169, 175, 179, 185, 189, 195, 199,
    209, 219, 229, 239, 249, 259, 269, 279, 289, 299,
]

# –ì—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–∏–ª–∞ –∑–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –∑–∞ –ö–∞—Ç–µ–≥–æ—Ä–∏—è_3
#   - –ú—ä–∂–∫–∏ —Ä–æ–¥ (–º.—Ä.): –ú—ä–∂–∫–∏/–î–∞–º—Å–∫–∏/–î–µ—Ç—Å–∫–∏ (—Å—É–∏—Ç—à—ä—Ä—Ç, –ø–∞–Ω—Ç–∞–ª–æ–Ω, –∫–ª–∏–Ω, –µ–∫–∏–ø, –µ–ª–µ–∫, –ø–æ—Ç–Ω–∏–∫)
#   - –ñ–µ–Ω—Å–∫–∏ —Ä–æ–¥ (–∂.—Ä.): –ú—ä–∂–∫–∞/–î–∞–º—Å–∫–∞/–î–µ—Ç—Å–∫–∞ (—Ç–µ–Ω–∏—Å–∫–∞, —Ä–∏–∑–∞, —á–∞–Ω—Ç–∞, —Ä–∞–Ω–∏—Ü–∞, –∂–∏–ª–µ—Ç–∫–∞, —à–∞–ø–∫–∞)
#   - –°—Ä–µ–¥–µ–Ω —Ä–æ–¥ (—Å—Ä.—Ä.): –ú—ä–∂–∫–æ/–î–∞–º—Å–∫–æ/–î–µ—Ç—Å–∫–æ (—è–∫–µ, –±—é—Å—Ç–∏–µ, –±–æ–¥–∏)
#   - –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–æ —á–∏—Å–ª–æ (–º–Ω.—á.): –ú—ä–∂–∫–∏/–î–∞–º—Å–∫–∏/–î–µ—Ç—Å–∫–∏ (–º–∞—Ä–∞—Ç–æ–Ω–∫–∏, –∫–µ—Ü–æ–≤–µ, —á–æ—Ä–∞–ø–∏, –±–æ–∫—Å–µ—Ä–∫–∏, —Å–∞–Ω–¥–∞–ª–∏)

FEMININE_WORDS = {'—Ç–µ–Ω–∏—Å–∫–∞', '—Ä–∏–∑–∞', '—á–∞–Ω—Ç–∞', '—Ä–∞–Ω–∏—Ü–∞', '–∂–∏–ª–µ—Ç–∫–∞', '—à–∞–ø–∫–∞'}
NEUTER_WORDS = {'—è–∫–µ', '–±—é—Å—Ç–∏–µ', '–±–æ–¥–∏'}
PLURAL_WORDS = {'–º–∞—Ä–∞—Ç–æ–Ω–∫–∏', '–∫–µ—Ü–æ–≤–µ', '—á–æ—Ä–∞–ø–∏', '–±–æ–∫—Å–µ—Ä–∫–∏', '—Å–∞–Ω–¥–∞–ª–∏', '–ø—Ä–µ–¥–ø–∞–∑–Ω–∏ –∫–æ—Ä–∏'}

GENDER_PREFIXES = {
    '–ú—ä–∂–µ': {'m': '–ú—ä–∂–∫–∏', 'f': '–ú—ä–∂–∫–∞', 'n': '–ú—ä–∂–∫–æ', 'pl': '–ú—ä–∂–∫–∏'},
    '–ñ–µ–Ω–∏': {'m': '–î–∞–º—Å–∫–∏', 'f': '–î–∞–º—Å–∫–∞', 'n': '–î–∞–º—Å–∫–æ', 'pl': '–î–∞–º—Å–∫–∏'},
    '–î–µ—Ü–∞': {'m': '–î–µ—Ç—Å–∫–∏', 'f': '–î–µ—Ç—Å–∫–∞', 'n': '–î–µ—Ç—Å–∫–æ', 'pl': '–î–µ—Ç—Å–∫–∏'},
    '–£–Ω–∏—Å–µ–∫—Å': {'m': '–£–Ω–∏—Å–µ–∫—Å', 'f': '–£–Ω–∏—Å–µ–∫—Å', 'n': '–£–Ω–∏—Å–µ–∫—Å', 'pl': '–£–Ω–∏—Å–µ–∫—Å'},
    '–ú–æ–º—á–µ—Ç–∞': {'m': '–î–µ—Ç—Å–∫–∏', 'f': '–î–µ—Ç—Å–∫–∞', 'n': '–î–µ—Ç—Å–∫–æ', 'pl': '–î–µ—Ç—Å–∫–∏'},
    '–ú–æ–º–∏—á–µ—Ç–∞': {'m': '–î–µ—Ç—Å–∫–∏', 'f': '–î–µ—Ç—Å–∫–∞', 'n': '–î–µ—Ç—Å–∫–æ', 'pl': '–î–µ—Ç—Å–∫–∏'},
}


# ============================================================
# –§–£–ù–ö–¶–ò–ò
# ============================================================

def load_tipo_dictionary(uploaded_file):
    """–ó–∞—Ä–µ–∂–¥–∞ —Ä–µ—á–Ω–∏–∫ TIPO –æ—Ç Excel —Ñ–∞–π–ª —Å –ª–∏—Å—Ç Traduzioni.
    –ü–æ–¥–¥—ä—Ä–∂–∞ –¥–≤–∞ —Ñ–æ—Ä–º–∞—Ç–∞:
    - –û–ø—Ä–æ—Å—Ç–µ–Ω —Ñ–æ—Ä–º–∞—Ç: 3 –∫–æ–ª–æ–Ω–∏ (Inglese, Bulgaro intermedio, Bulgaro)
    - SOFIA —Ñ–æ—Ä–º–∞—Ç: 13+ –∫–æ–ª–æ–Ω–∏ (ARTICOLI, ..., –∫–æ–ª–æ–Ω–∞ 12 = –æ–ø—Ä–æ—Å—Ç–µ–Ω –±—ä–ª–≥–∞—Ä—Å–∫–∏)
    """
    try:
        df_trad = pd.read_excel(uploaded_file, sheet_name='Traduzioni')
        mapping = {}
        num_cols = len(df_trad.columns)

        for _, row in df_trad.iterrows():
            eng = row.iloc[0]  # –ü—ä—Ä–≤–∞ –∫–æ–ª–æ–Ω–∞ = –∞–Ω–≥–ª–∏–π—Å–∫–∏

            if num_cols >= 13:
                # SOFIA —Ñ–æ—Ä–º–∞—Ç: –∏–∑–ø–æ–ª–∑–≤–∞ –∫–æ–ª–æ–Ω–∞ 12 (–æ–ø—Ä–æ—Å—Ç–µ–Ω –±—ä–ª–≥–∞—Ä—Å–∫–∏)
                bg = row.iloc[12]
            elif num_cols >= 3:
                # –û–ø—Ä–æ—Å—Ç–µ–Ω —Ñ–æ—Ä–º–∞—Ç: –∏–∑–ø–æ–ª–∑–≤–∞ –ø–æ—Å–ª–µ–¥–Ω–∞—Ç–∞ –∫–æ–ª–æ–Ω–∞ (Bulgaro)
                bg = row.iloc[num_cols - 1]
            else:
                continue

            if pd.notna(eng) and pd.notna(bg) and str(eng).strip() and str(bg).strip():
                eng_str = str(eng).strip()
                bg_str = str(bg).strip()
                if eng_str not in ('INGLESE', 'ARTICOLI', 'Inglese') and bg_str != '0':
                    mapping[eng_str] = bg_str

        return mapping if mapping else None
    except Exception:
        return None


def round_to_price_point(value):
    """–ó–∞–∫—Ä—ä–≥–ª—è –¥–æ –Ω–∞–π-–±–ª–∏–∑–∫–∞—Ç–∞ —Ç—ä—Ä–≥–æ–≤—Å–∫–∞ —Ü–µ–Ω–æ–≤–∞ —Ç–æ—á–∫–∞. –ü—Ä–∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ -> –Ω–∞–≥–æ—Ä–µ."""
    best = None
    best_diff = float('inf')
    for pp in PRICE_POINTS:
        diff = abs(pp - value)
        if diff < best_diff or (diff == best_diff and pp > best):
            best = pp
            best_diff = diff
    return best


def get_cat3_value(cat1, tipo_bg):
    """–ì–µ–Ω–µ—Ä–∏—Ä–∞ –ö–∞—Ç–µ–≥–æ—Ä–∏—è_3 —Å –ø—Ä–∞–≤–∏–ª–Ω–∞ –≥—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∞ —Ñ–æ—Ä–º–∞."""
    if pd.isna(cat1) or pd.isna(tipo_bg):
        return ''

    tipo_lower = str(tipo_bg).lower().strip()
    prefixes = GENDER_PREFIXES.get(cat1)
    if not prefixes:
        return f'{cat1} {tipo_bg}'

    if tipo_lower in FEMININE_WORDS:
        prefix = prefixes['f']
    elif tipo_lower in NEUTER_WORDS:
        prefix = prefixes['n']
    elif tipo_lower in PLURAL_WORDS:
        prefix = prefixes['pl']
    else:
        prefix = prefixes['m']  # –ø–æ –ø–æ–¥—Ä–∞–∑–±–∏—Ä–∞–Ω–µ –º—ä–∂–∫–∏ —Ä–æ–¥

    return f'{prefix} {tipo_bg.lower()}'


def process_file(df, price_multiplier=1.8, tipo_map=None, brand="NIKE"):
    """–û–±—Ä–∞–±–æ—Ç–≤–∞ DataFrame —Å –≤—Å–∏—á–∫–∏ 23 —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏."""

    if tipo_map is None:
        tipo_map = TIPO_MAP

    result = pd.DataFrame()

    # 1-10: –û—Å–Ω–æ–≤–Ω–∏ –∫–æ–ª–æ–Ω–∏
    result['Cod+Color'] = df['Art.num']
    result['Cod.Nike'] = df['Code']
    result['Cod Color'] = df['Art.num'].astype(str).str.split('-', n=1).str[1]
    result['TAGLIA'] = df['SizeConverted']
    result['SKU Completo'] = df['Art.num'].astype(str) + '-' + df['SizeConverted'].astype(str)
    result['DESCRIZIONE'] = df['Description']
    result['STAG.'] = df['Season']
    result['BARCODE'] = df['Barcode']
    result['QTA'] = df['Dlv.qty']
    result['FPC Price w/o VAT in EUR'] = df['FPC Price w/o VAT in EUR'].round(2)

    # 11: PRZ DETT
    result['PRZ DETT'] = (df['FPC Price w/o VAT in EUR'] * price_multiplier).round(2)

    # 12: PREZZO NEGOZIO
    result['PREZZO NEGOZIO'] = result['PRZ DETT'].apply(round_to_price_point)

    # 13: BRAND
    result['BRAND'] = brand

    # 14-16: –û—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏ –∫–æ–ª–æ–Ω–∏ –ø—Ä–µ–∏–º–µ–Ω—É–≤–∞–Ω–∏
    result['CATEGORIA'] = df['Division']
    result['GENERE'] = df['Gender']
    result['TIPO'] = df['Silhouette']

    # 17: CATEG.BG
    result['CATEG.BG'] = df['Division'].map(DIVISION_MAP)

    # NEW: –ì—Ä—É–ø–∞ = BRAND + CATEG.BG (Uppercase)
    result['–ì—Ä—É–ø–∞'] = (
        result['BRAND'].fillna('').astype(str) + ' ' +
        result['CATEG.BG'].fillna('').astype(str)
    ).str.upper().str.strip()

    # 18: GEN.BG
    result['GEN.BG'] = df['Gender'].map(GENDER_MAP)

    # 19: TIPO.BG
    result['TIPO.BG'] = df['Silhouette'].map(tipo_map)

    # 20: –ö–∞—Ç–µ–≥–æ—Ä–∏—è_1
    result['–ö–∞—Ç–µ–≥–æ—Ä–∏—è_1'] = result['GEN.BG'].map(SESSO_MAP)

    # 21: –ö–∞—Ç–µ–≥–æ—Ä–∏—è_2
    result['–ö–∞—Ç–µ–≥–æ—Ä–∏—è_2'] = result.apply(
        lambda row: f"{CATEGORY2_PREFIX.get(row['–ö–∞—Ç–µ–≥–æ—Ä–∏—è_1'], '')} {row['CATEG.BG']}"
        if pd.notna(row['–ö–∞—Ç–µ–≥–æ—Ä–∏—è_1']) and pd.notna(row['CATEG.BG']) else '',
        axis=1
    )

    # 22: –ö–∞—Ç–µ–≥–æ—Ä–∏—è_3
    result['–ö–∞—Ç–µ–≥–æ—Ä–∏—è_3'] = result.apply(
        lambda row: get_cat3_value(row['–ö–∞—Ç–µ–≥–æ—Ä–∏—è_1'], row['TIPO.BG']),
        axis=1
    )

    # 23: Site Description = –ö–∞—Ç–µ–≥–æ—Ä–∏—è_3 + Brand + DESCRIZIONE
    result['Site Description'] = (
        result['–ö–∞—Ç–µ–≥–æ—Ä–∏—è_3'].fillna('').astype(str) + ' ' +
        result['BRAND'].fillna('').astype(str) + ' ' +
        result['DESCRIZIONE'].fillna('').astype(str)
    ).str.strip()

    return result


def to_excel_bytes(df, sheet_name='Sheet1'):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–∞ DataFrame –≤ bytes –∑–∞ –∏–∑—Ç–µ–≥–ª—è–Ω–µ.
    –°–ø–µ—Ü–∏–∞–ª–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞ MultiIndex —Ö–µ–¥—ä—Ä–∏ –ø—Ä–∏ index=False.
    """
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        if isinstance(df.columns, pd.MultiIndex):
            # –ó–∞–ø–∏—Å –Ω–∞ MultiIndex —Ö–µ–¥—ä—Ä–∏—Ç–µ —Ä—ä—á–Ω–æ, —Ç—ä–π –∫–∞—Ç–æ pandas –∏–º–∞ –±—ä–≥ —Å index=False
            # –†–µ–¥ 1: Titles (numeric IDs)
            # –†–µ–¥ 2: Subtitles (Bulgarian names)
            header_df = pd.DataFrame(df.columns.tolist()).T
            header_df.to_excel(writer, index=False, header=False, sheet_name=sheet_name)
            # –ó–∞–ø–∏—Å –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ –æ—Ç —Ä–µ–¥ 3
            df.to_excel(writer, index=False, header=False, sheet_name=sheet_name, startrow=2)
        else:
            df.to_excel(writer, index=False, sheet_name=sheet_name)
    return output.getvalue()


# ============================================================
# –ò–ù–¢–ï–†–§–ï–ô–° STREAMLIT
# ============================================================

st.title("–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ —Ñ–∞–π–ª–æ–≤–µ Nike")
st.markdown("–ö–∞—á–µ—Ç–µ Excel —Ñ–∞–π–ª –∑–∞ –¥–æ—Å—Ç–∞–≤–∫–∞, –æ–±—Ä–∞–±–æ—Ç–µ—Ç–µ –≥–æ –∏ –∏–∑—Ç–µ–≥–ª–µ—Ç–µ —Ä–µ–∑—É–ª—Ç–∞—Ç–∞.")

# --- –°–¢–†–ê–ù–ò–ß–ù–ê –õ–ï–ù–¢–ê ---
with st.sidebar:
    st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")

    profile = st.selectbox(
        "–ü—Ä–æ—Ñ–∏–ª –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞",
        ["Nike Ballistic"],
        help="–ò–∑–±–µ—Ä–µ—Ç–µ –ø—Ä–æ—Ñ–∏–ª –∑–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–∞ –¥–∞–Ω–Ω–∏"
    )

    st.divider()

    price_multiplier = st.number_input(
        "–ú–Ω–æ–∂–∏—Ç–µ–ª –Ω–∞ —Ü–µ–Ω–∞ (PRZ DETT)",
        min_value=1.0,
        max_value=5.0,
        value=1.8,
        step=0.1,
        help="–¶–µ–Ω–∞—Ç–∞ FPC —Å–µ —É–º–Ω–æ–∂–∞–≤–∞ –ø–æ —Ç–∞–∑–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç"
    )

    brand_name = st.text_input(
        "–ú–∞—Ä–∫–∞",
        value="NIKE",
        help="–ò–º–µ –Ω–∞ –º–∞—Ä–∫–∞—Ç–∞ –∑–∞ –∫–æ–ª–æ–Ω–∞ BRAND"
    )

    warehouse_name = st.text_input(
        "–°–∫–ª–∞–¥ (–∑–∞ Import Gensoft)",
        value="",
        placeholder="–í—ä–≤–µ–¥–µ—Ç–µ —Å–∫–ª–∞–¥..."
    )

    supplier_name = st.text_input(
        "–î–æ—Å—Ç–∞–≤—á–∏–∫ (–∑–∞ Import Gensoft)",
        value="",
        placeholder="–í—ä–≤–µ–¥–µ—Ç–µ –¥–æ—Å—Ç–∞–≤—á–∏–∫..."
    )

    st.divider()

    st.subheader("–†–µ—á–Ω–∏–∫ –∑–∞ –ø—Ä–µ–≤–æ–¥–∏")
    dict_file = st.file_uploader(
        "–ö–∞—á–µ—Ç–µ —Ä–µ—á–Ω–∏–∫ (–ø–æ –∏–∑–±–æ—Ä)",
        type=['xlsx'],
        help="Excel —Ñ–∞–π–ª —Å –ª–∏—Å—Ç 'Traduzioni' –∑–∞ —Å—ä–ø–æ—Å—Ç–∞–≤—è–Ω–µ –Ω–∞ TIPO. –ê–∫–æ –Ω–µ –µ –∫–∞—á–µ–Ω, —Å–µ –∏–∑–ø–æ–ª–∑–≤–∞ –≤–≥—Ä–∞–¥–µ–Ω–∏—è—Ç —Ä–µ—á–Ω–∏–∫."
    )

    custom_tipo_map = None
    if dict_file is not None:
        custom_tipo_map = load_tipo_dictionary(dict_file)
        if custom_tipo_map:
            st.success(f"–†–µ—á–Ω–∏–∫—ä—Ç –µ –∑–∞—Ä–µ–¥–µ–Ω: {len(custom_tipo_map)} –∑–∞–ø–∏—Å–∞")
        else:
            st.warning("–ù–µ –º–æ–∂–µ –¥–∞ —Å–µ –ø—Ä–æ—á–µ—Ç–µ —Ä–µ—á–Ω–∏–∫—ä—Ç. –ò–∑–ø–æ–ª–∑–≤–∞ —Å–µ –≤–≥—Ä–∞–¥–µ–Ω–∏—è—Ç —Ä–µ—á–Ω–∏–∫.")

    st.divider()
    st.caption("v1.0 - –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ —Ñ–∞–π–ª–æ–≤–µ Gensoft")

# --- –û–°–ù–û–í–ù–ê –û–ë–õ–ê–°–¢ ---

uploaded_file = st.file_uploader(
    "–ö–∞—á–µ—Ç–µ Excel —Ñ–∞–π–ª –∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞",
    type=['xlsx', 'xls'],
    help="–§–∞–π–ª –∑–∞ –¥–æ—Å—Ç–∞–≤–∫–∞ Nike/Ballistic —Å –∫–æ–ª–æ–Ω–∏: Art.num, Code, SizeConverted –∏ –¥—Ä."
)

if uploaded_file is not None:
    # –ß–µ—Ç–µ–Ω–µ –Ω–∞ —Ñ–∞–π–ª–∞
    try:
        df_input = pd.read_excel(uploaded_file)
    except Exception as e:
        st.error(f"–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ —á–µ—Ç–µ–Ω–µ –Ω–∞ —Ñ–∞–π–ª–∞: {e}")
        st.stop()

    st.subheader("–ü—Ä–µ–≥–ª–µ–¥ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏—è —Ñ–∞–π–ª")
    col1, col2 = st.columns(2)
    with col1:
        st.metric("–†–µ–¥–æ–≤–µ", len(df_input))
    with col2:
        st.metric("–ö–æ–ª–æ–Ω–∏", len(df_input.columns))

    with st.expander("–ü–æ–∫–∞–∂–∏ –ø—Ä–µ–≥–ª–µ–¥ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏—Ç–µ –¥–∞–Ω–Ω–∏", expanded=False):
        st.dataframe(df_input.head(10), use_container_width=True)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–∏—Ç–µ –∫–æ–ª–æ–Ω–∏
    required_cols = ['Art.num', 'Code', 'SizeConverted', 'Description', 'Season',
                     'Barcode', 'Dlv.qty', 'FPC Price w/o VAT in EUR',
                     'Division', 'Gender', 'Silhouette']
    missing_cols = [c for c in required_cols if c not in df_input.columns]

    if missing_cols:
        st.error(f"–õ–∏–ø—Å–≤–∞—â–∏ –∫–æ–ª–æ–Ω–∏ –≤—ä–≤ —Ñ–∞–π–ª–∞: **{', '.join(missing_cols)}**")
        st.info(f"–ù–∞–º–µ—Ä–µ–Ω–∏ –∫–æ–ª–æ–Ω–∏: {', '.join(df_input.columns.tolist())}")
        st.stop()

    st.divider()

    # –ë—É—Ç–æ–Ω –∑–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞
    if st.button("–û–±—Ä–∞–±–æ—Ç–∏ —Ñ–∞–π–ª–∞", type="primary", use_container_width=True):
        with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ —Ö–æ–¥..."):
            tipo_map_to_use = custom_tipo_map if custom_tipo_map else TIPO_MAP

            df_output = process_file(
                df_input,
                price_multiplier=price_multiplier,
                tipo_map=tipo_map_to_use,
                brand=brand_name,
            )

            st.session_state['df_output'] = df_output
            st.session_state['elaborated'] = True

    # –ü–æ–∫–∞–∑–≤–∞–Ω–µ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∞
    if st.session_state.get('elaborated', False):
        df_output = st.session_state['df_output']

        st.subheader("–†–µ–∑—É–ª—Ç–∞—Ç –æ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∞—Ç–∞")

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("–†–µ–¥–æ–≤–µ", len(df_output))
        with col2:
            st.metric("–ö–æ–ª–æ–Ω–∏", len(df_output.columns))
        with col3:
            # –ë—Ä–æ–π –ª–∏–ø—Å–≤–∞—â–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
            missing_count = df_output.isna().sum().sum()
            unmapped_tipo = df_output['TIPO.BG'].isna().sum()
            unmapped_gen = df_output['GEN.BG'].isna().sum()
            if unmapped_tipo > 0 or unmapped_gen > 0:
                st.metric("–ù–µ—Å—ä–ø–æ—Å—Ç–∞–≤–µ–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏", f"TIPO: {unmapped_tipo}, GEN: {unmapped_gen}")
            else:
                st.metric("–°—Ç–∞—Ç—É—Å", "–í—Å–∏—á–∫–æ –µ —Å—ä–ø–æ—Å—Ç–∞–≤–µ–Ω–æ!")

        # –ü–æ–∫–∞–∑–≤–∞–Ω–µ –Ω–∞ –Ω–µ—Å—ä–ø–æ—Å—Ç–∞–≤–µ–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
        if df_output['TIPO.BG'].isna().any():
            unmapped = df_output[df_output['TIPO.BG'].isna()]['TIPO'].unique()
            st.warning(f"–ù–µ–ø—Ä–µ–≤–µ–¥–µ–Ω–∏ TIPO: **{', '.join(str(x) for x in unmapped)}**")

        if df_output['GEN.BG'].isna().any():
            unmapped = df_output[df_output['GEN.BG'].isna()]['GENERE'].unique()
            st.warning(f"–ù–µ–ø—Ä–µ–≤–µ–¥–µ–Ω–∏ GENERE: **{', '.join(str(x) for x in unmapped)}**")

        with st.expander("–ü–æ–∫–∞–∂–∏ –ø—Ä–µ–≥–ª–µ–¥ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∞", expanded=True):
            st.dataframe(df_output.head(20), use_container_width=True)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        with st.expander("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"):
            tab1, tab2, tab3 = st.tabs(["–ö–∞—Ç–µ–≥–æ—Ä–∏–∏", "–¶–µ–Ω–∏", "–ü–æ–ª"])
            with tab1:
                st.write("**CATEG.BG**")
                st.dataframe(df_output['CATEG.BG'].value_counts().reset_index())
                st.write("**–ö–∞—Ç–µ–≥–æ—Ä–∏—è_1**")
                st.dataframe(df_output['–ö–∞—Ç–µ–≥–æ—Ä–∏—è_1'].value_counts().reset_index())
            with tab2:
                st.write("**PREZZO NEGOZIO - —Ä–∞–∑–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ**")
                st.dataframe(df_output['PREZZO NEGOZIO'].value_counts().sort_index().reset_index())
            with tab3:
                st.write("**GEN.BG**")
                st.dataframe(df_output['GEN.BG'].value_counts().reset_index())

        st.divider()

        # –ò–∑—Ç–µ–≥–ª—è–Ω–µ
        data = datetime.now().strftime("%d%m%Y")
        filename = f"Elaborato_({data}).xlsx"

        excel_bytes = to_excel_bytes(df_output)

        col_dl1, col_dl2 = st.columns(2)
        col_dl3, col_dl4 = st.columns(2)

        with col_dl1:
            st.download_button(
                label="–ò–∑—Ç–µ–≥–ª–∏ –æ–±—Ä–∞–±–æ—Ç–µ–Ω —Ñ–∞–π–ª",
                data=excel_bytes,
                file_name=filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="primary",
                use_container_width=True,
            )

        # --- –û–ü–ê–ö–û–í–™–ß–ï–ù –õ–ò–°–¢ ---
        df_packing = df_output.groupby('Cod+Color', sort=False).agg(
            DESCRIZIONE=('DESCRIZIONE', 'first'),
            CATEG_BG=('CATEG.BG', 'first'),
            QTA=('QTA', 'sum'),
            PREZZO_NEGOZIO=('PREZZO NEGOZIO', 'first'),
        ).reset_index()

        # –î–æ–±–∞–≤–∏ —Ä–µ–¥ —Å —Ç–æ—Ç–∞–ª –≤ –∫—Ä–∞—è
        packing_total_row = pd.DataFrame({
            'Cod+Color': ['TOTALE'],
            'DESCRIZIONE': [''],
            'CATEG_BG': [''],
            'QTA': [df_packing['QTA'].sum()],
            'PREZZO_NEGOZIO': ['']
        })
        df_packing = pd.concat([df_packing, packing_total_row], ignore_index=True)

        # –ü—Ä–µ–∏–º–µ–Ω—É–≤–∞–Ω–µ –Ω–∞ –∫–æ–ª–æ–Ω–∏ –Ω–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏
        df_packing = df_packing.rename(columns={
            'Cod+Color': '–ö–æ–¥',
            'DESCRIZIONE': '–û–ø–∏—Å–∞–Ω–∏–µ',
            'CATEG_BG': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
            'QTA': '–ö–æ–ª–∏—á.',
            'PREZZO_NEGOZIO': '–¶–µ–Ω–∞',
        })

        packing_bytes = to_excel_bytes(df_packing)
        packing_filename = f"Packing_list_({data}).xlsx"

        with col_dl2:
            st.download_button(
                label="–ò–∑—Ç–µ–≥–ª–∏ Packing List",
                data=packing_bytes,
                file_name=packing_filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="secondary",
                use_container_width=True,
            )

        # --- –û–ü–ê–ö–û–í–™–ß–ï–ù –õ–ò–°–¢ –î–ï–¢–ê–ô–õ–ï–ù ---
        df_packing_dett = df_output.groupby(['Cod.Nike', 'Cod Color', 'TAGLIA'], sort=False).agg(
            DESCRIZIONE=('DESCRIZIONE', 'first'),
            CATEG_BG=('CATEG.BG', 'first'),
            QTA=('QTA', 'sum'),
            PREZZO_NEGOZIO=('PREZZO NEGOZIO', 'first'),
        ).reset_index()

        # –î–æ–±–∞–≤–∏ —Ä–µ–¥ —Å —Ç–æ—Ç–∞–ª –≤ –∫—Ä–∞—è
        total_row = pd.DataFrame({
            'Cod.Nike': ['TOTALE'],
            'Cod Color': [''],
            'TAGLIA': [''],
            'DESCRIZIONE': [''],
            'CATEG_BG': [''],
            'QTA': [df_packing_dett['QTA'].sum()],
            'PREZZO_NEGOZIO': ['']
        })
        df_packing_dett = pd.concat([df_packing_dett, total_row], ignore_index=True)

        # –ü—Ä–µ–∏–º–µ–Ω—É–≤–∞–Ω–µ –Ω–∞ –∫–æ–ª–æ–Ω–∏ –Ω–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –∑–∞ –¥–µ—Ç–∞–π–ª–Ω–∏—è —Å–ø–∏—Å—ä–∫
        df_packing_dett = df_packing_dett.rename(columns={
            'Cod.Nike': '–ö–û–î',
            'Cod Color': '–¶–≤—è—Ç',
            'TAGLIA': '–†–∞–∑–º–µ—Ä',
            'DESCRIZIONE': '–û–ø–∏—Å–∞–Ω–∏–µ',
            'CATEG_BG': '–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
            'QTA': '–ö–æ–ª–∏—á.',
            'PREZZO_NEGOZIO': '–¶–µ–Ω–∞'
        })

        packing_dett_bytes = to_excel_bytes(df_packing_dett)
        packing_dett_filename = f"Packing_list_dett_({data}).xlsx"

        with col_dl3:
            st.download_button(
                label="–ò–∑—Ç–µ–≥–ª–∏ Packing List –î–µ—Ç–∞–π–ª–µ–Ω",
                data=packing_dett_bytes,
                file_name=packing_dett_filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="secondary",
                use_container_width=True,
            )

        # --- IMPORT GENSOFT ---
        # –î–µ—Ñ–∏–Ω–∏—Ä–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏ –∑–∞ –Ω–æ–≤–∞—Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å –¥–≤–∞ —Ä–µ–¥–∞ —Ö–µ–¥—ä—Ä (ID –∏ –ò–º–µ)
        gensoft_data = {
            ("", "–°–∫–ª–∞–¥"): [warehouse_name] * len(df_output),
            ("", "–ì–ª–∞–≤–Ω–∞ –≥—Ä—É–ø–∞"): df_output['BRAND'],
            ("", "–ì—Ä—É–ø–∞"): df_output['–ì—Ä—É–ø–∞'],
            ("", "–°—Ç–æ–∫–∞"): df_output['Cod.Nike'],
            ("", "–°–µ—Ä./–ø–∞—Ä—Ç. –Ω–æ–º–µ—Ä"): df_output['BARCODE'],
            ("", "–ö–æ–¥ –Ω–∞ —Å—Ç–æ–∫–∞"): df_output['Site Description'],
            ("", "–ë–∞—Ä–∫–æ–¥ –Ω–∞ —Å—Ç–æ–∫–∞"): "",
            ("", "–ú—è—Ä–∫–∞"): "–±—Ä.",
            ("", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"): df_output['QTA'],
            ("", "–î–æ—Å—Ç–∞–≤–Ω–∞ —Ü–µ–Ω–∞"): df_output['FPC Price w/o VAT in EUR'],
            ("", "–î–æ—Å—Ç–∞–≤–Ω–∞ –≤–∞–ª—É—Ç–∞"): "eur",
            ("", "–¶–µ–Ω–∞ –Ω–∞ –¥—Ä–µ–±–Ω–æ"): df_output['PREZZO NEGOZIO'],
            ("", "–í–∞–ª—É—Ç–∞ –Ω–∞ –¥—Ä–µ–±–Ω–æ"): "eur",
            ("", "–î–æ—Å—Ç–∞–≤—á–∏–∫"): [supplier_name] * len(df_output),
            ("", "–ö-–≤–æ –∑–∞ –ø–æ—Ä—ä—á–≤–∞–Ω–µ"): df_output['QTA'],
            ("", "–¶–µ–Ω–∞"): df_output['FPC Price w/o VAT in EUR'],
            ("", "–í–∞–ª—É—Ç–∞"): "eur",
            ("", "–ë–µ–ª–µ–∂–∫–∞"): df_output['Cod+Color'],
            ("", "–ê–∫—Ç–∏–≤–Ω–∞"): "Y",
            ("", "–ê–∫—Ç–∏–≤–Ω–∞ –∑–∞ Web"): "Y",
            ("", "–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –≤ —Å–º–µ—Ç–∫–∏"): "–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è",
            ("", "–ü—Ä–æ—Ü–µ–Ω—Ç –î–î–°"): "",
            # –ù–æ–≤–∏ –∫–æ–ª–æ–Ω–∏ —Å ID-—Ç–∞
            ("14", "–†–∞–∑–º–µ—Ä —Å–∞–π—Ç"): df_output['TAGLIA'],
            ("107", "–¶–≤—è—Ç —Å–∞–π—Ç"): df_output['Cod Color'],
            ("13", "SKU"): df_output['SKU Completo'],
            ("109", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è 1"): df_output['–ö–∞—Ç–µ–≥–æ—Ä–∏—è_1'],
            ("110", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è 2"): df_output['–ö–∞—Ç–µ–≥–æ—Ä–∏—è_2'],
            ("111", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è 3"): df_output['–ö–∞—Ç–µ–≥–æ—Ä–∏—è_3'],
            ("15", "–ë—Ä–∞–Ω–¥"): df_output['BRAND'],
            ("2", "–ü–æ–ª"): df_output['GEN.BG'],
            ("5", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è"): df_output['CATEG.BG'],
            ("6", "–°–µ–∑–æ–Ω"): df_output['STAG.'],
            ("108", "–¶–µ–Ω–∞ —Å—Ä–≤. —Å–∞–π—Ç"): df_output['PREZZO NEGOZIO'],
            ("113", "–ö–æ–¥ —Ç–∞–±–ª–∏—Ü–∞ –∑–∞ —Ä–∞–∑–º–µ—Ä–∏"): "",
            ("103", "–î–æ—Å—Ç–≤—á–∏–∫"): [supplier_name] * len(df_output),
        }

        df_gensoft = pd.DataFrame(gensoft_data)
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞ MultiIndex –∫–æ–ª–æ–Ω–∏
        df_gensoft.columns = pd.MultiIndex.from_tuples(df_gensoft.columns)

        gensoft_bytes = to_excel_bytes(df_gensoft)
        gensoft_filename = f"Import_Gensoft_({data}).xlsx"

        with col_dl4:
            st.download_button(
                label="–ò–∑—Ç–µ–≥–ª–∏ Import Gensoft",
                data=gensoft_bytes,
                file_name=gensoft_filename,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="secondary",
                use_container_width=True,
            )

        # –ü—Ä–µ–≥–ª–µ–¥ –Ω–∞ Packing List
        with st.expander("–ü—Ä–µ–≥–ª–µ–¥ –Ω–∞ Packing List"):
            st.dataframe(df_packing, use_container_width=True)

        # –ü—Ä–µ–≥–ª–µ–¥ –Ω–∞ Packing List –î–µ—Ç–∞–π–ª–µ–Ω
        with st.expander("–ü—Ä–µ–≥–ª–µ–¥ –Ω–∞ Packing List –î–µ—Ç–∞–π–ª–µ–Ω"):
            st.dataframe(df_packing_dett, use_container_width=True)

        # –ü—Ä–µ–≥–ª–µ–¥ –Ω–∞ Import Gensoft
        with st.expander("–ü—Ä–µ–≥–ª–µ–¥ –Ω–∞ Import Gensoft"):
            # –§–ª–∞—Ç–≤–∞–Ω–µ –Ω–∞ MultiIndex –∑–∞ –ø—Ä–µ–≥–ª–µ–¥ –≤ Streamlit (–∑–∞ –∏–∑–±—è–≥–≤–∞–Ω–µ –Ω–∞ –≥—Ä–µ—à–∫–∏ –≤ –¥–∏—Å–ø–ª–µ—è)
            df_gensoft_preview = df_gensoft.copy()
            if isinstance(df_gensoft_preview.columns, pd.MultiIndex):
                df_gensoft_preview.columns = [
                    f"{col[0]} {col[1]}".strip() if col[0] else col[1] 
                    for col in df_gensoft_preview.columns
                ]
            st.dataframe(df_gensoft_preview, use_container_width=True)

else:
    st.info("–ö–∞—á–µ—Ç–µ Excel —Ñ–∞–π–ª, –∑–∞ –¥–∞ –∑–∞–ø–æ—á–Ω–µ—Ç–µ –æ–±—Ä–∞–±–æ—Ç–∫–∞—Ç–∞.")

    # ============================================================
    # –î–û–ö–£–ú–ï–ù–¢–ê–¶–ò–Ø / –ü–û–ú–û–©
    # ============================================================
    st.divider()
    col_help1, col_help2 = st.columns(2)

    with col_help1:
        with st.expander("–ù–µ–æ–±—Ö–æ–¥–∏–º–∏ –∫–æ–ª–æ–Ω–∏ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏—è —Ñ–∞–π–ª"):
            st.markdown("""
            –§–∞–π–ª—ä—Ç —Ç—Ä—è–±–≤–∞ –¥–∞ —Å—ä–¥—ä—Ä–∂–∞ —Å–ª–µ–¥–Ω–∏—Ç–µ –∫–æ–ª–æ–Ω–∏ (–∏–º–µ–Ω–∞ –æ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª–Ω–∏—è Ballistic —Ñ–∞–π–ª):
            - `Art.num`
            - `Code`
            - `SizeConverted`
            - `Description`
            - `Season`
            - `Barcode`
            - `Dlv.qty`
            - `FPC Price w/o VAT in EUR`
            - `Division`
            - `Gender`
            - `Silhouette`
            """)

    with col_help2:
        with st.expander("–ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–∏ –∫–æ–ª–æ–Ω–∏ (Elaborato)"):
            st.markdown("""
            –û–±—Ä–∞–±–æ—Ç–∫–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞ **24 –∫–æ–ª–æ–Ω–∏**:

            | # | –ö–æ–ª–æ–Ω–∞ | –ò–∑—Ç–æ—á–Ω–∏–∫ |
            |---|--------|----------|
            | 1 | Cod+Color | Art.num |
            | 2 | Cod.Nike | Code |
            | 3 | Cod Color | —á–∞—Å—Ç—Ç–∞ —Å–ª–µ–¥ "-" –æ—Ç Art.num |
            | 4 | TAGLIA | SizeConverted |
            | 5 | SKU Completo | Art.num + "-" + SizeConverted |
            | 6 | DESCRIZIONE | Description |
            | 7 | STAG. | Season |
            | 8 | BARCODE | Barcode |
            | 9 | QTA | Dlv.qty |
            | 10 | FPC Price w/o VAT in EUR | —Å—ä—â–∞—Ç–∞ |
            | 11 | PRZ DETT | FPC Price x –º–Ω–æ–∂–∏—Ç–µ–ª |
            | 12 | PREZZO NEGOZIO | —Ç—ä—Ä–≥–æ–≤—Å–∫–æ –∑–∞–∫—Ä—ä–≥–ª—è–Ω–µ |
            | 13 | BRAND | Nike |
            | 14 | CATEGORIA | Division |
            | 15 | GENERE | Gender |
            | 16 | TIPO | Silhouette |
            | 17 | CATEG.BG | Division –ø—Ä–µ–≤–µ–¥–µ–Ω–æ –Ω–∞ –ë–ì |
            | 18 | –ì—Ä—É–ø–∞ | Brand + CATEG.BG (–≥–ª–∞–≤–Ω–∏ –±—É–∫–≤–∏) |
            | 19 | GEN.BG | Gender –ø—Ä–µ–≤–µ–¥–µ–Ω–æ –Ω–∞ –ë–ì |
            | 20 | TIPO.BG | Silhouette –ø—Ä–µ–≤–µ–¥–µ–Ω–æ –Ω–∞ –ë–ì |
            | 21 | –ö–∞—Ç–µ–≥–æ—Ä–∏—è_1 | –ì—Ä—É–ø–∏—Ä–∞–Ω–µ –ø–æ –ø–æ–ª |
            | 22 | –ö–∞—Ç–µ–≥–æ—Ä–∏—è_2 | –ü—Ä–µ—Ñ–∏–∫—Å –ø–æ–ª + –ö–∞—Ç–µ–≥–æ—Ä–∏—è |
            | 23 | –ö–∞—Ç–µ–≥–æ—Ä–∏—è_3 | –ì—Ä–∞–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ—Ñ–∏–∫—Å + –¢–∏–ø |
            | 24 | Site Description | –ö–∞—Ç–µ–≥–æ—Ä–∏—è_3 + Brand + –û–ø–∏—Å–∞–Ω–∏–µ |
            """)

    with st.expander("–û–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ —Ñ–∞–π–ª–æ–≤–µ—Ç–µ –∑–∞ –∏–∑—Ç–µ–≥–ª—è–Ω–µ"):
        st.markdown("""
        1. **–û–±—Ä–∞–±–æ—Ç–µ–Ω —Ñ–∞–π–ª (Elaborato)**: –ü—ä–ª–Ω–∏—è—Ç —Å–ø–∏—Å—ä–∫ —Å –≤—Å–∏—á–∫–∏ 24 —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏.
        2. **Packing List**: –û–±–æ–±—â–µ–Ω –ø–æ –∞—Ä—Ç–∏–∫—É–ª –∏ —Ü–≤—è—Ç.
        3. **Packing List –î–µ—Ç–∞–π–ª–µ–Ω**: –û–±–æ–±—â–µ–Ω –ø–æ –∞—Ä—Ç–∏–∫—É–ª, —Ü–≤—è—Ç –∏ —Ä–∞–∑–º–µ—Ä, —Å –ø—Ä–µ–≤–µ–¥–µ–Ω–∏ –∫–æ–ª–æ–Ω–∏.
        4. **Import Gensoft**: –°–ø–µ—Ü–∏–∞–ª–µ–Ω —Ñ–æ—Ä–º–∞—Ç –∑–∞ –¥–∏—Ä–µ–∫—Ç–µ–Ω –∏–º–ø–æ—Ä—Ç –≤ Gensoft, –∏–∑–ø–æ–ª–∑–≤–∞—â –º–∞–Ω—É–∞–ª–Ω–∏—Ç–µ –ø–æ–ª–µ—Ç–∞ –æ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏—Ç–µ.
        """)
